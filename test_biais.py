import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import chi2_contingency, ks_2samp
import warnings
warnings.filterwarnings('ignore')

# Configuration matplotlib pour √©viter les probl√®mes de compatibilit√©
import matplotlib
matplotlib.use('Agg' if 'matplotlib.backends' in str(matplotlib.get_backend()) else 'TkAgg')

class BiasDetector:
    def __init__(self, train_path, valid_path):
        """
        Initialise le d√©tecteur de biais avec les chemins des fichiers CSV
        
        Args:
            train_path (str): Chemin vers le fichier CSV du train set
            valid_path (str): Chemin vers le fichier CSV du validation set
        """
        print("üîç Chargement des donn√©es...")
        self.train_df = pd.read_csv(train_path)
        self.valid_df = pd.read_csv(valid_path)
        
        print(f"üìä Train set: {self.train_df.shape[0]} lignes, {self.train_df.shape[1]} colonnes")
        print(f"‚úÖ Validation set: {self.valid_df.shape[0]} lignes, {self.valid_df.shape[1]} colonnes")
        
        # V√©rifier que les colonnes sont identiques
        self.common_columns = list(set(self.train_df.columns) & set(self.valid_df.columns))
        if len(self.common_columns) != len(self.train_df.columns):
            print("‚ö†Ô∏è  Attention: Les datasets n'ont pas exactement les m√™mes colonnes")
        
        self.bias_report = {}
        
    def detect_column_types(self):
        """D√©tecte automatiquement les types de colonnes"""
        numerical_cols = []
        categorical_cols = []
        
        for col in self.common_columns:
            if self.train_df[col].dtype in ['int64', 'float64']:
                # V√©rifier si c'est vraiment num√©rique ou cat√©goriel avec peu de valeurs
                unique_values = len(self.train_df[col].unique())
                if unique_values <= 20:  # Seuil arbitraire
                    categorical_cols.append(col)
                else:
                    numerical_cols.append(col)
            else:
                categorical_cols.append(col)
                
        return numerical_cols, categorical_cols
    
    def analyze_numerical_bias(self, numerical_cols):
        """Analyse le biais pour les variables num√©riques"""
        print("\nüìà Analyse des variables num√©riques...")
        
        n_cols = min(3, len(numerical_cols))
        if n_cols == 0:
            print("Aucune variable num√©rique trouv√©e")
            return
            
        n_rows = (len(numerical_cols) + n_cols - 1) // n_cols
        
        fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))
        if n_rows == 1 and n_cols == 1:
            axes = [axes]
        elif n_rows == 1:
            axes = axes
        else:
            axes = axes.flatten()
        
        for i, col in enumerate(numerical_cols):
            if i >= len(axes):
                break
                
            ax = axes[i]
            
            # Histogrammes superpos√©s
            ax.hist(self.train_df[col].dropna(), alpha=0.7, label='Train', bins=30, density=True)
            ax.hist(self.valid_df[col].dropna(), alpha=0.7, label='Validation', bins=30, density=True)
            ax.set_title(f'{col}', fontsize=14, fontweight='bold')
            ax.set_xlabel(col)
            ax.set_ylabel('Densit√©')
            ax.legend()
            ax.grid(True, alpha=0.3)
            
            # Test de Kolmogorov-Smirnov
            try:
                ks_stat, p_value = ks_2samp(
                    self.train_df[col].dropna(), 
                    self.valid_df[col].dropna()
                )
                
                # Classification du biais
                if p_value < 0.01:
                    bias_level = "√âLEV√â"
                    color = "red"
                elif p_value < 0.05:
                    bias_level = "MOD√âR√â"
                    color = "orange"
                else:
                    bias_level = "FAIBLE"
                    color = "green"
                
                ax.text(0.05, 0.95, f'KS p-value: {p_value:.4f}\nBiais: {bias_level}', 
                       transform=ax.transAxes, verticalalignment='top',
                       bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),
                       color=color, fontweight='bold')
                
                self.bias_report[col] = {
                    'type': 'numerical',
                    'ks_statistic': ks_stat,
                    'p_value': p_value,
                    'bias_level': bias_level,
                    'train_mean': self.train_df[col].mean(),
                    'valid_mean': self.valid_df[col].mean(),
                    'train_std': self.train_df[col].std(),
                    'valid_std': self.valid_df[col].std()
                }
                
            except Exception as e:
                print(f"Erreur lors du test KS pour {col}: {e}")
        
        # Masquer les axes vides
        for j in range(len(numerical_cols), len(axes)):
            axes[j].set_visible(False)
            
        plt.tight_layout()
        plt.suptitle('Distribution des Variables Num√©riques - Train vs Validation', 
                     fontsize=16, fontweight='bold', y=1.02)
        plt.show()
    
    def analyze_categorical_bias(self, categorical_cols):
        """Analyse le biais pour les variables cat√©gorielles"""
        print("\nüìä Analyse des variables cat√©gorielles...")
        
        if len(categorical_cols) == 0:
            print("Aucune variable cat√©gorielle trouv√©e")
            return
        
        n_cols = min(2, len(categorical_cols))
        n_rows = (len(categorical_cols) + n_cols - 1) // n_cols
        
        fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 6*n_rows))
        if n_rows == 1 and n_cols == 1:
            axes = [axes]
        elif n_rows == 1:
            axes = axes
        else:
            axes = axes.flatten()
        
        for i, col in enumerate(categorical_cols):
            if i >= len(axes):
                break
                
            ax = axes[i]
            
            # Compter les valeurs
            train_counts = self.train_df[col].value_counts(normalize=True)
            valid_counts = self.valid_df[col].value_counts(normalize=True)
            
            # Cr√©er un DataFrame pour la visualisation
            all_categories = set(train_counts.index) | set(valid_counts.index)
            comparison_df = pd.DataFrame({
                'Train': [train_counts.get(cat, 0) for cat in all_categories],
                'Validation': [valid_counts.get(cat, 0) for cat in all_categories]
            }, index=list(all_categories))
            
            # Graphique en barres
            comparison_df.plot(kind='bar', ax=ax, width=0.8)
            ax.set_title(f'{col}', fontsize=14, fontweight='bold')
            ax.set_xlabel('Cat√©gories')
            ax.set_ylabel('Proportion')
            ax.legend()
            ax.tick_params(axis='x', rotation=45)
            ax.grid(True, alpha=0.3)
            
            # Test du Chi-carr√©
            try:
                # Cr√©er la table de contingence
                train_counts_abs = self.train_df[col].value_counts()
                valid_counts_abs = self.valid_df[col].value_counts()
                
                all_cats = set(train_counts_abs.index) | set(valid_counts_abs.index)
                contingency_table = np.array([
                    [train_counts_abs.get(cat, 0) for cat in all_cats],
                    [valid_counts_abs.get(cat, 0) for cat in all_cats]
                ])
                
                chi2, p_value, dof, expected = chi2_contingency(contingency_table)
                
                # Classification du biais
                if p_value < 0.01:
                    bias_level = "√âLEV√â"
                    color = "red"
                elif p_value < 0.05:
                    bias_level = "MOD√âR√â"
                    color = "orange"
                else:
                    bias_level = "FAIBLE"
                    color = "green"
                
                ax.text(0.05, 0.95, f'Chi¬≤ p-value: {p_value:.4f}\nBiais: {bias_level}', 
                       transform=ax.transAxes, verticalalignment='top',
                       bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),
                       color=color, fontweight='bold')
                
                self.bias_report[col] = {
                    'type': 'categorical',
                    'chi2_statistic': chi2,
                    'p_value': p_value,
                    'bias_level': bias_level,
                    'train_distribution': train_counts.to_dict(),
                    'valid_distribution': valid_counts.to_dict()
                }
                
            except Exception as e:
                print(f"Erreur lors du test Chi¬≤ pour {col}: {e}")
        
        # Masquer les axes vides
        for j in range(len(categorical_cols), len(axes)):
            if j < len(axes):
                axes[j].set_visible(False)
            
        plt.tight_layout()
        plt.suptitle('Distribution des Variables Cat√©gorielles - Train vs Validation', 
                     fontsize=16, fontweight='bold', y=1.02)
        plt.show()
    
    def create_summary_report(self):
        """Cr√©e un rapport de synth√®se"""
        print("\n" + "="*60)
        print("üìã RAPPORT DE SYNTH√àSE - D√âTECTION DE BIAIS")
        print("="*60)
        
        total_vars = len(self.bias_report)
        high_bias_vars = [col for col, info in self.bias_report.items() 
                         if info['bias_level'] == '√âLEV√â']
        medium_bias_vars = [col for col, info in self.bias_report.items() 
                           if info['bias_level'] == 'MOD√âR√â']
        low_bias_vars = [col for col, info in self.bias_report.items() 
                        if info['bias_level'] == 'FAIBLE']
        
        print(f"\nüìä Variables analys√©es: {total_vars}")
        print(f"üî¥ Biais √âLEV√â: {len(high_bias_vars)} variables")
        print(f"üü° Biais MOD√âR√â: {len(medium_bias_vars)} variables") 
        print(f"üü¢ Biais FAIBLE: {len(low_bias_vars)} variables")
        
        if high_bias_vars:
            print(f"\n‚ö†Ô∏è  Variables avec biais √âLEV√â:")
            for var in high_bias_vars:
                info = self.bias_report[var]
                print(f"   ‚Ä¢ {var} (p-value: {info['p_value']:.4f})")
        
        if medium_bias_vars:
            print(f"\n‚ö° Variables avec biais MOD√âR√â:")
            for var in medium_bias_vars:
                info = self.bias_report[var]
                print(f"   ‚Ä¢ {var} (p-value: {info['p_value']:.4f})")
        
        # Graphique de synth√®se
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # Graphique en camembert des niveaux de biais
        bias_counts = [len(high_bias_vars), len(medium_bias_vars), len(low_bias_vars)]
        labels = ['Biais √âlev√©', 'Biais Mod√©r√©', 'Biais Faible']
        colors = ['#ff6b6b', '#feca57', '#48dbfb']
        
        wedges, texts, autotexts = ax1.pie(bias_counts, labels=labels, colors=colors, 
                                          autopct='%1.1f%%', startangle=90)
        ax1.set_title('R√©partition des Niveaux de Biais', fontsize=14, fontweight='bold')
        
        # Graphique des p-values
        variables = list(self.bias_report.keys())
        p_values = [self.bias_report[var]['p_value'] for var in variables]
        colors_bar = ['red' if p < 0.01 else 'orange' if p < 0.05 else 'green' for p in p_values]
        
        bars = ax2.bar(range(len(variables)), p_values, color=colors_bar, alpha=0.7)
        ax2.axhline(y=0.05, color='red', linestyle='--', alpha=0.7, label='Seuil Œ±=0.05')
        ax2.axhline(y=0.01, color='darkred', linestyle='--', alpha=0.7, label='Seuil Œ±=0.01')
        ax2.set_xlabel('Variables')
        ax2.set_ylabel('P-value')
        ax2.set_title('P-values des Tests de Biais', fontsize=14, fontweight='bold')
        ax2.set_xticks(range(len(variables)))
        ax2.set_xticklabels(variables, rotation=45, ha='right')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        # Recommandations
        print("\nüí° RECOMMANDATIONS:")
        if len(high_bias_vars) > 0:
            print("   üî¥ Action urgente requise! Plusieurs variables montrent un biais √©lev√©.")
            print("   üîß Consid√©rez un r√©√©chantillonnage ou une stratification.")
        elif len(medium_bias_vars) > 0:
            print("   üü° Attention mod√©r√©e requise pour certaines variables.")
            print("   üîç Surveillez ces variables lors de l'√©valuation du mod√®le.")
        else:
            print("   üü¢ Excellent! Aucun biais significatif d√©tect√©.")
            print("   ‚úÖ Votre validation set semble bien repr√©sentatif.")
    
    def run_full_analysis(self):
        """Lance l'analyse compl√®te"""
        print("üöÄ D√©but de l'analyse de biais...")
        
        # Configuration du style des graphiques
        plt.style.use('seaborn-v0_8')
        sns.set_palette("husl")
        
        # D√©tection des types de colonnes
        numerical_cols, categorical_cols = self.detect_column_types()
        
        print(f"\nüî¢ Variables num√©riques d√©tect√©es: {len(numerical_cols)}")
        print(f"üìù Variables cat√©gorielles d√©tect√©es: {len(categorical_cols)}")
        
        # Analyse des variables num√©riques
        if numerical_cols:
            self.analyze_numerical_bias(numerical_cols)
        
        # Analyse des variables cat√©gorielles  
        if categorical_cols:
            self.analyze_categorical_bias(categorical_cols)
        
        # Rapport de synth√®se
        self.create_summary_report()
        
        print("\n‚úÖ Analyse termin√©e!")
        return self.bias_report

# Fonction utilitaire pour lancer l'analyse
def analyze_bias(train_csv_path, validation_csv_path):
    """
    Fonction principale pour analyser le biais entre train et validation set
    
    Args:
        train_csv_path (str): Chemin vers le fichier CSV du train set
        validation_csv_path (str): Chemin vers le fichier CSV du validation set
    
    Returns:
        dict: Rapport d√©taill√© de l'analyse de biais
    """
    detector = BiasDetector(train_csv_path, validation_csv_path)
    return detector.run_full_analysis()

# Exemple d'utilisation
if __name__ == "__main__":
    # üîß MODIFIEZ CES LIGNES AVEC VOS CHEMINS DE FICHIERS üîß
    TRAIN_PATH = "waiting_times_train.csv"  # ‚Üê LIGNE √Ä MODIFIER : Chemin vers votre train set
    VALIDATION_PATH = "waiting_times_X_test_final.csv"  # ‚Üê LIGNE √Ä MODIFIER : Chemin vers votre validation set
    
    # Lancer l'analyse
    try:
        bias_report = analyze_bias(TRAIN_PATH, VALIDATION_PATH)
        print("\nüéâ Analyse compl√©t√©e avec succ√®s!")
    except FileNotFoundError as e:
        print(f"‚ùå Erreur: Fichier non trouv√© - {e}")
        print("üí° Assurez-vous que les chemins vers vos fichiers CSV sont corrects")
    except Exception as e:
        print(f"‚ùå Erreur inattendue: {e}")